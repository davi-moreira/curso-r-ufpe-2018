---
title: "Introdução à Linguagem R - Workshop"
subtitle: Encontro 3
header-includes:
  - \usepackage[english,brazil]{babel}
author: "Davi Moreira"
date: "`r format(Sys.time(), '%d de %B, %Y')`"
output:
  pdf_document:
    toc: yes
    number_sections: true
  html_document:
    code_folding: hide
    collapsed: yes
    theme: united
    toc: yes
    toc_float: yes
  urlcolor: blue  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# tex / pandoc options for pdf creation
x <- Sys.getenv("PATH")
y <- paste(x, "/miktex/bin", sep=";")
Sys.setenv(PATH = y)
```

\newpage 
<!-- COMENTARIO --> 

# Encontro 3

## Dúvidas e revisão do conteúdo do encontro prévio

- 15 minutos serão reservados para dúvidas e revisão do conteúdo do encontro prévio.

## Estrutura do encontro 3

3. REQUISITANDO DADOS DA WEB
- Extraindo conteúdo da página: rvest, xml2, css e xpath;
- Baixando arquivos da web: pdf, csv, excel;

Até o final do encontro o aluno deverá ser capaz de:

- Obter e organizar conteúdo da web de forma automatizada 
- Desenvolver programas capazes de acessar páginas, realizar consultas e fazer 
download de arquivos


<!-- \newpage --> 


# `for`, `while` e nossas próprias funções

As funções `for()` e `while()` implementam o controle de fluxo no `R`. A escolha de qual usar vai depender do contexto e objetivo do código.

## `for`

```{r, results = 'asis', eval = FALSE}
# for()

for (i in 1:10) {
  print (i)
}
```

## `while`

```{r, results = 'asis', eval = FALSE}
# while ()
x = 1

while (x <= 10 )  {
  print (x)
  x = x + 1
}
```

## Criando funções

```{r, results = 'asis', eval = FALSE}
soma_dois <- function(x) { x + 2 }

soma_dois(4)

obj <- 1:15

soma_dois(obj)

```


# `purrr` package

```{r fig.width=7, fig.height=70, fig.align="center", echo=FALSE}
library(png)
library(grid)
 img <- readPNG("./imagens/purrr.png")
 grid.raster(img)
```

Para uma boa introdução sobre o pacote, veja o seguinte material:

- [\textcolor{blue}{Curso R - Purrr}](http://material.curso-r.com/purrr/)
- [\textcolor{blue}{Happy R Users Purrr – Tutorial}](https://www.rstudio.com/resources/videos/happy-r-users-purrr-tutorial/)
- [\textcolor{blue}{Purrr  Tutorial}](https://jennybc.github.io/purrr-tutorial/index.html)

```{r, results = 'asis', eval = FALSE}
install.packages("tidyverse")
library(purrr)
```

```{r, results = 'asis', eval = FALSE}
soma_dois <- function(x) { x + 2 }
obj <- 1:15

obj <- map(obj, soma_dois)
obj

# como a funcao map retorna uma lista, podemos usar sufixos para retornar um tipo 
# de vetor específico

map_dbl(obj, soma_dois)

```

# Web Scraping

Web Scraping é uma técnica de extração de dados utilizada para coletar conteúdo publicado
na internet por meio de procedimentos automatizados.

## Tipos de conteúdo disponível

### Código fonte 
É possível conhecer o código fonte de um site ao clicar com o botão direito do mouse
no conteúdo da página. 

* [\textcolor{blue}{Wikipedia}](https://pt.wikipedia.org/wiki/Lista_de_munic%C3%ADpios_do_Brasil_por_IDH)

```{r fig.width=5, fig.height=50, fig.align="center", echo=FALSE}
library(png)
library(grid)
 img <- readPNG("./imagens/wiki.png")
 grid.raster(img)
```

* [\textcolor{blue}{Deputados}](http://www.camara.leg.br/internet/deputado/DepNovos_Lista.asp?Legislatura=54&Partido=QQ&SX=QQ&Todos=None&UF=QQ&condic=QQ&forma=lista&nome=&ordem=nome&origem=)

```{r fig.width=5, fig.height=50, fig.align="center", echo=FALSE}
library(png)
library(grid)
 img <- readPNG("./imagens/deputados.png")
 grid.raster(img)
```

### Arquivos para download 
Além do conteúdo diretamente publicado na página, pode ser de interesse fazer o download de
arquivos disponíveis. 

* [\textcolor{blue}{Censo Escolar}](http://inep.gov.br/microdados)

```{r fig.width=5, fig.height=50, fig.align="center", echo=FALSE}
library(png)
library(grid)
 img <- readPNG("./imagens/INEP.png")
 grid.raster(img)
```

* [\textcolor{blue}{TCE}](https://www.tce.pe.gov.br/internet/index.php/relatorios-de-gestao-fiscal-2)

```{r fig.width=5, fig.height=50, fig.align="center", echo=FALSE}
library(png)
library(grid)
 img <- readPNG("./imagens/tce.png")
 grid.raster(img)
```

### Web services

Os [\textcolor{blue}{Web services}](https://pt.wikipedia.org/wiki/Web_service) são componentes que 
permitem às aplicações enviar e receber dados. Um dos motivos que tornam os Web Services atrativos é o fato deste modelo ser baseado em tecnologias standards, em particular XML e HTTP (Hypertext Transfer Protocol). Os Web Services são utilizados para disponibilizar serviços interativos na Web, podendo ser acessados por outras aplicações. O objetivo dos Web Services é a comunicação de aplicações através da Internet.

* [\textcolor{blue}{Web service da Câmara dos Deputados}](http://www2.camara.leg.br/transparencia/dados-abertos/dados-abertos-legislativo/webservices)

```{r fig.width=5, fig.height=50, fig.align="center", echo=FALSE}
library(png)
library(grid)
 img <- readPNG("./imagens/webservice.png")
 grid.raster(img)
```

## Pacotes para raspagem de dados

Há diversos pacotes para raspagem de dados com o `R`. Abaixo segue um lista com os
principais. Para referências sobre seu uso, consulte os links indicados, 
[\textcolor{blue}{este tutorial sobre o `rvest`}](https://www.datacamp.com/community/tutorials/r-web-scraping-rvest) e 
[\textcolor{blue}{este capitulo sobre web scraping}](http://material.curso-r.com/scrape/). 

* [\textcolor{blue}{`httr`}](https://cran.r-project.org/web/packages/httr/vignettes/quickstart.html)
* [\textcolor{blue}{`xml2`}](https://cran.r-project.org/web/packages/xml2/xml2.pdf)
* [\textcolor{blue}{`rvest`}](https://blog.rstudio.com/2014/11/24/rvest-easy-web-scraping-with-r/)

Como o site [\textcolor{blue}{Curso-R}](http://material.curso-r.com/scrape/) destaca, esses pacotes não são suficientes para acessar todo tipo de conteúdo da web. Páginas com conteúdo produzido na linguagem `javascript`, 
por exemplo, precisam de outras ferramentas para acesso a seu conteúdo. Nesses casos, é necessário 
“simular” um navegador que acessa a página web e realiza consultas. Uma das melhores ferramentas para 
isso é o selenium, abaixo indicado.

* [\textcolor{blue}{`RSelenium`}](https://ropensci.org/tutorials/rselenium_tutorial/)

# Obtendo conteúdo 

## Etapas para raspagem de dados na web

1. Conhecer detalhadamente o caminho para acesso aos dados
2. Armazenar todos os caminhos de acesso aos dados de forma amigável ao programa
3. Obter os dados
4. Processar os dados obtidos

## Conteúdo de páginas

### **Código Fonte:** 
Podemos facilmente obter o código fonte de um endereço na internet com o uso da 
função `readLines`.

```{r, results = 'asis', eval = FALSE}
if(require(tidyverse) == F) install.packages('tidyverse'); require(tidyverse)
if(require(rvest) == F) install.packages('rvest'); require(rvest)
if(require(httr) == F) install.packages('httr'); require(httr)
if(require(xml2) == F) install.packages('xml2'); require(xml2)

#################################################################################
# ETAPA 1. Conhecer detalhadamente o caminho para acesso aos dados
# ETAPA 2. Armazenar todos os caminhos de acesso aos dados de forma amigável ao programa

# defnindo endereço da web
link <- "https://pt.wikipedia.org/wiki/Lista_de_munic%C3%ADpios_do_Brasil_por_IDH"

#################################################################################
# ETAPA 3. Obter os dados
conteudo <- readLines(link)  # obtem o codigo fonte
head(conteudo)

# Vamos verificar a posição de Fenando de Noronha no vetor 'conteudo'.
grep("Fernando", conteudo)
conteudo[769 + 4]  # linha com o IDH de Fernando de Noronha

conteudo[769 + 9]  # Próximo município
conteudo[769 + 9 + 9] # Parece haver um padrão

# Com o objeto 'conteudo' já seria possível obter os dados para criacão do data frame 
# com o IDH dos municípios.

#################################################################################
# ETAPA 4. Processar os dados obtidos 
# vamos selecionar todas linhas que apresentem os nomes dos municipios

grep("São Caetano", conteudo)  # 94
grep("Santa Maria", conteudo)  # 1066

indice <- 94
nomes_munic <- NULL
i <- 1

while(indice < 1066){
      if(i==1){
            nomes_munic[i] <- conteudo[indice]
      } else{
        nomes_munic[i] <- conteudo[indice+9]
      }
          indice <- indice + 9
          i <- i + 1
}

nomes_munic

?regex

nomes_munic <- gsub("[[:print:]]+\">", "", nomes_munic)
nomes_munic <- gsub("</a>", "", nomes_munic)
nomes_munic <- gsub("</b>", "", nomes_munic)
nomes_munic <- gsub("<b>", "", nomes_munic)

nomes_munic

# Poderíamos realizar procedimento semelhante para obter os IDHs municipais, os
# nomes da UFs e assim construir nosso data.frame
```

#### Atividade prática: 

```{r, results = 'asis', eval = FALSE}
# Identifique em qual linha do vetor 'conteudo' está Pernambuco. Adapte o exemplo visto
# para obter um vetor com os nomes das UFs.
```

### **Obtendo tabelas em html:**

```{r, results = 'asis', eval = FALSE}
#################################################################################
# ETAPA 1. Conhecer detalhadamente o caminho para acesso aos dados
# ETAPA 2. Armazenar todos os caminhos de acesso aos dados de forma amigável ao programa
link <- "https://pt.wikipedia.org/wiki/Lista_de_munic%C3%ADpios_do_Brasil_por_IDH"


#################################################################################
# ETAPA 3. Obter os dados
# ETAPA 4. Processar os dados obtidos 

bd <- link %>%
  httr::GET() %>%
  xml2::read_html() %>%
  rvest::html_node('table') %>%
  rvest::html_table(header = TRUE)

bd
class(bd)

# E quando o link possui mais de uma tabela?

#################################################################################
# ETAPA 1. Conhecer detalhadamente o caminho para acesso aos dados
# ETAPA 2. Armazenar todos os caminhos de acesso aos dados de forma amigável ao programa
link <- "https://pt.wikipedia.org/wiki/Lista_de_campe%C3%B5es_do_futebol_brasileiro"

#################################################################################
# ETAPA 3. Obter os dados
bd <- link %>%
  httr::GET() %>%
  xml2::read_html() %>%
  rvest::html_nodes('table') %>%  # veja que utilizamos outra função  
  rvest::html_table(header = TRUE)

class(bd)

#################################################################################
# ETAPA 4. Processar os dados obtidos 
bd1 <- bd[[1]]
bd2 <- bd[[2]]
bd3 <- bd[[3]]

```

#### Atividade prática: 

```{r, results = 'asis', eval = FALSE}
# Com o link abaixo, desenvolva um progrma que obtenha o endereço das páginas de todos 
# os deputados federais da atual legislatura alocando-os num vetor.

link <- "http://www.camara.leg.br/internet/deputado/DepNovos_Lista.asp?
          Legislatura=54&Partido=QQ&SX=QQ&Todos=None&UF=QQ&condic=QQ&forma=lista&
          nome=&ordem=nome&origem="
```

<!-- COMENTARIO --> 
<!-- link %>% read_html %>% html_nodes("a") %>% html_attr('href') --> 
<!-- COMENTARIO --> 

## Download de arquivos

```{r, results = 'asis', eval = FALSE}
#################################################################################
# ETAPA 1. Conhecer detalhadamente o caminho para acesso aos dados
link <- "https://www.tce.pe.gov.br/internet/index.php/relatorios-de-gestao-fiscal-2"

#################################################################################
# ETAPA 2. Armazenar todos os caminhos de acesso aos dados de forma amigável ao programa
link_relatorios <- link %>% read_html %>% html_nodes("a") %>% html_attr('href')
link_relatorios <- link_relatorios[grep("rdg", link_relatorios)]

#################################################################################
# ETAPA 3. Obter os dados
mainDir <- paste(getwd(), "/dados/", sep = "")
subDir <- "relatorios_tce"

dir.create(file.path(mainDir, subDir), showWarnings = FALSE)

setwd("./dados/relatorios_tce/")

for( i in 1:length(link_relatorios)){
   download.file(link_relatorios[i], paste0(as.character(c(2017:2006))[i], ".pdf"), mode="auto")
}

download.file(link_relatorios)

#################################################################################
# ETAPA 4. Processar os dados obtidos 
if(require(pdftools) == F) install.packages('pdftools'); require(pdftools)

setwd("./relatorios_tce/")
rdg2017 <- pdf_text("2017.pdf")

length(rdg2017)
head(rdg2017)

# Preparando data.frame para nuvem de palavras
# Instalando pacotes
if(require(tm) == F) install.packages('tm'); require(tm)
if(require(SnowballC) == F) install.packages('SnowballC'); require(SnowballC)
if(require(wordcloud) == F) install.packages('wordcloud'); require(wordcloud)
if(require(RColorBrewer) == F) install.packages('RColorBrewer'); require(RColorBrewer)

docs <- Corpus(VectorSource(rdg2017))

# convertendo o texto em caixa baixa
docs <- tm_map(docs, content_transformer(tolower))

# removendo números
docs <- tm_map(docs, removeNumbers)

# removendo stopwords (artigos, preposições, etc.)
docs <- tm_map(docs, removeWords, stopwords("portuguese"))

# removendo pontuação
docs <- tm_map(docs, removePunctuation)

# eliminando espaços 
docs <- tm_map(docs, stripWhitespace)

# stemming
docs <- tm_map(docs, stemDocument, language = "portuguese")

# document term matrix - matriz de documentos e termos
dtm <- TermDocumentMatrix(docs)

# criando data.frame
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d)
d <- d[-3,]  # removendo caracter especial
head(d)

# nuvem de palavras
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

```

```{r fig.width=3, fig.height=30, fig.align="center", echo=FALSE}
library(png)
library(grid)
 img <- readPNG("./imagens/nuvem.png")
 grid.raster(img)
```

#### Atividade prática: 

```{r, results = 'asis', eval = FALSE}
# Crie um novo diretório e desenvolva um programa que faça o download dos arquivos 
# em formato .zip na página de dados do Censo Escolar (http://inep.gov.br/microdados).
# Para otimizar nosso tempo, selecione apenas os microdados do Censo Escolar de
# 1996, 2006, 2016.
```

## Web service

```{r, results = 'asis', eval = FALSE}
if(require(httr) == F) install.packages('httr'); require(httr);
if(require(XML) == F) install.packages('XML'); require(XML);
if(require(xml2) == F) install.packages('xml2'); require(xml2);

#################################################################################
# ETAPA 1. Conhecer detalhadamente o caminho para acesso aos dados
# ETAPA 2. Armazenar todos os caminhos de acesso aos dados de forma amigável ao programa

link <- paste0("http://www.camara.leg.br/SitCamaraWS/Deputados.asmx/ObterDeputados")

#################################################################################
# ETAPA 3. Obter os dados
response <- GET(link)

#################################################################################
# ETAPA 4. Processar os dados obtidos 
data <- xmlParse(response, encoding = "UTF-8")
ls <- xmlToList(data)

names(ls$deputado)

ideCadastro <- NULL
condicao <- NULL
matricula <- NULL
idParlamentar <- NULL
nome <- NULL
nomeParlamentar <- NULL
urlFoto <- NULL
sexo <- NULL
uf <- NULL
partido <- NULL
email <- NULL

for(i in 1:length(ls)){
  ideCadastro[i] <- ls[[i]]$ideCadastro
  condicao[i] <- ls[[i]]$condicao
  matricula[i] <- ls[[i]]$matricula
  idParlamentar[i] <- ls[[i]]$idParlamentar
  nome[i] <- ls[[i]]$nome
  nomeParlamentar[i] <- ls[[i]]$nomeParlamentar
  urlFoto[i] <- ls[[i]]$urlFoto
  sexo[i] <- ls[[i]]$sexo
  uf[i] <- ls[[i]]$uf
  partido[i] <- ls[[i]]$partido
  email[i] <- ls[[i]]$email
}

bd <- data.frame(ideCadastro, condicao, matricula, idParlamentar, nome, 
                 nomeParlamentar, urlFoto, sexo, uf, partido, email)

head(bd)
```

#### Atividade prática: 

Com a base de dados obtida, utilize a variável ideCadastro para obter detalhes dos
Deputados Federais que representam o Estado de Pernambuco, confome permitido pelo 
link [\textcolor{blue}{ObterDetalhesDeputado}](http://www2.camara.leg.br/transparencia/dados-abertos/dados-abertos-legislativo/webservices/deputados/obterDetalhesDeputado)

# Atividade Prática - Encontro 2
 
* Com os dados do Censo Escolar de 2016, construa uma base de dados municipal que apresente o 
número de turmas, docentes e matrículas por município. Em seguida faça a união dessa base com 
o [\textcolor{blue}{Atlas dos Municípios}](http://www.atlasbrasil.org.br/2013/pt/download/) (atlas2013_dadosbrutos_pt.xlsx), 
utilizando os dados de 2010 presentes na aba "MUN 91-00-10".

# Atividade Prática - Encontro 3

```{r, results = 'asis', eval = FALSE}
# Utilizando o vetor de endereços das páginas dos deputados federais obtido com o link abaixo,

link <- "http://www.camara.leg.br/internet/deputado/DepNovos_Lista.asp?
        Legislatura=54&Partido=QQ&SX=QQ&Todos=None&UF=QQ&condic=QQ&forma=lista&
        nome=&ordem=nome&origem="

# Acesse cada uma das páginas e monte uma base de dados que tenha as seguintes 
# informações biográficas de cada deputado: Nome, Data de Nascimento, Naturalidade, 
# Profissao, Filiacao e Escolaridade.

# Qual a proporção de Deputados Federais com ensino superior?
```

<!-- * * Envie o script de seu trabalho para: davi.moreira@gmail.com.
Coloque o assunto de seu e-mail no seguinte formato: Curso R TCE - Turma "M/V" - Aula "N": "NOME DO ALUNO". --> 


# Links úteis para o próximo encontro

* [\textcolor{blue}{Análise exploratória}](http://r4ds.had.co.nz/exploratory-data-analysis.html)
* [\textcolor{blue}{Regressão Linear}](http://r-statistics.co/Linear-Regression.html)
* [\textcolor{blue}{Pacote ggplot2}](https://ggplot2.tidyverse.org/)
* [\textcolor{blue}{Data Visualisation}](http://r4ds.had.co.nz/data-visualisation.html)
* [\textcolor{blue}{CursoR: ggplot2}](http://material.curso-r.com/ggplot/)
